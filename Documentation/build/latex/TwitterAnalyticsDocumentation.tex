%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional
  \DeclareUnicodeCharacter{"00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{"2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{"2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{"2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{"251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{"2572}{\textbackslash}
 \else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{2572}{\textbackslash}
 \fi
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage[dontkeepoldnames]{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}


\title{Twitter Analytics Documentation}
\date{Jun 08, 2018}
\release{0.1}
\author{Deepak Saini, Abhishek Gupta}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}


Twitter generates millions of tweets each day. A vast amount of information is hence available for different kinds of analyses. The end users of these analyses however, may or may not be technically proficient. This necessitates the need of a system that can absorb such large amounts of data and at the same time, provide an intuitive abstraction over this data. This abstraction should allow the end users to specify different kinds of analyses without going into the technicalities of the implementation.

In this demonstration, we introduce a system that tries to meet precisely the above needs. Running on streaming data, the system provides an abstraction which allows the user to specify real time events in the stream, for which he wishes to be notified. Also, acting as a data-store for the tweet network, the system provides another abstraction which allows the user to formulate complex queries on this historical data. We demonstrate both of these abstractions using an example of each, on real world data.

Here we provide a comprehenstive documentaion of each component of the system along with a documentation of the code.


\chapter{Introduction to twitter analytics system}
\label{\detokenize{introduction:welcome-to-twitter-analytics-documentation}}\label{\detokenize{introduction::doc}}\label{\detokenize{introduction:introduction-to-twitter-analytics-system}}

\chapter{Read data from twitter streaming API}
\label{\detokenize{twitter_stream::doc}}\label{\detokenize{twitter_stream:read-data-from-twitter-streaming-api}}

\chapter{Ingesting data into Neo4j}
\label{\detokenize{neo4j_data_ingestion::doc}}\label{\detokenize{neo4j_data_ingestion:ingesting-data-into-neo4j}}

\chapter{Ingesting data into MongoDB}
\label{\detokenize{mongoDB_data_ingestion::doc}}\label{\detokenize{mongoDB_data_ingestion:ingesting-data-into-mongodb}}

\section{Basics First}
\label{\detokenize{mongoDB_data_ingestion:basics-first}}
It has no network based data, simple data just sufficient for analytical queries.
We are storing some basic statistics of the tweets in mongoDB for faster access.  Presently we are storing :
\begin{itemize}
\item {} 
The number of times a hashtag, url, user mention has appeared in time intervals of 1 min.

\item {} 
The  basic  sentiment  associated  with  a  hashtag,  as  count  of  number  of  positive  and negative words

\end{itemize}

So how are we ingesting? We have two processes(most of the times running on different cores), with P1 keeping track of the statistics.  After every min, the data is put into a pipe which is received by P2 and then parallely put into mongoDB.


\section{Ingestion Rates}
\label{\detokenize{mongoDB_data_ingestion:ingestion-rates}}
AS expected, the ingestion rate into mongoDB shilw overlapping writing into diska nd building the new batch is faster than without parallelization. This can be observed in this image:

\noindent\sphinxincludegraphics{{image1}.png}


\section{Code Documentation}
\label{\detokenize{mongoDB_data_ingestion:code-documentation}}\label{\detokenize{mongoDB_data_ingestion:module-ingest_raw}}\index{ingest\_raw (module)}\index{Ingest (class in ingest\_raw)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Ingest}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{ingest\_raw.}\sphinxbfcode{Ingest}}{\emph{interval}}{}
Bases: \sphinxcode{object}
\index{aggregate() (ingest\_raw.Ingest method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Ingest.aggregate}}\pysiglinewithargsret{\sphinxbfcode{aggregate}}{}{}
\end{fulllineitems}

\index{exit() (ingest\_raw.Ingest method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Ingest.exit}}\pysiglinewithargsret{\sphinxbfcode{exit}}{}{}
\end{fulllineitems}

\index{insert\_tweet() (ingest\_raw.Ingest method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Ingest.insert_tweet}}\pysiglinewithargsret{\sphinxbfcode{insert\_tweet}}{\emph{tweet}}{}
update the in memory dictionaries

\end{fulllineitems}

\index{populate() (ingest\_raw.Ingest method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Ingest.populate}}\pysiglinewithargsret{\sphinxbfcode{populate}}{}{}
write to the mongoDB

\end{fulllineitems}

\index{worker() (ingest\_raw.Ingest method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Ingest.worker}}\pysiglinewithargsret{\sphinxbfcode{worker}}{\emph{q}}{}
\end{fulllineitems}


\end{fulllineitems}

\index{Timer (class in ingest\_raw)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{ingest\_raw.}\sphinxbfcode{Timer}}{\emph{interval}, \emph{function}, \emph{args=None}, \emph{kwargs=None}, \emph{iterations=1}, \emph{infinite=False}}{}
Bases: \sphinxcode{multiprocessing.context.Process}

Calls a function after a specified number of seconds:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t} \PYG{o}{=} \PYG{n}{Timer}\PYG{p}{(}\PYG{l+m+mf}{30.0}\PYG{p}{,} \PYG{n}{f}\PYG{p}{,} \PYG{n}{args}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{kwargs}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t}\PYG{o}{.}\PYG{n}{start}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t}\PYG{o}{.}\PYG{n}{cancel}\PYG{p}{(}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}stops the timer if it is still waiting}
\end{sphinxVerbatim}
\index{authkey (ingest\_raw.Timer attribute)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.authkey}}\pysigline{\sphinxbfcode{authkey}}
\end{fulllineitems}

\index{cancel() (ingest\_raw.Timer method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.cancel}}\pysiglinewithargsret{\sphinxbfcode{cancel}}{}{}
Stop the timer if it hasn’t already finished.

\end{fulllineitems}

\index{daemon (ingest\_raw.Timer attribute)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.daemon}}\pysigline{\sphinxbfcode{daemon}}
Return whether process is a daemon

\end{fulllineitems}

\index{exitcode (ingest\_raw.Timer attribute)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.exitcode}}\pysigline{\sphinxbfcode{exitcode}}
Return exit code of process or \sphinxtitleref{None} if it has yet to stop

\end{fulllineitems}

\index{ident (ingest\_raw.Timer attribute)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.ident}}\pysigline{\sphinxbfcode{ident}}
Return identifier (PID) of process or \sphinxtitleref{None} if it has yet to start

\end{fulllineitems}

\index{is\_alive() (ingest\_raw.Timer method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.is_alive}}\pysiglinewithargsret{\sphinxbfcode{is\_alive}}{}{}
Return whether process is alive

\end{fulllineitems}

\index{join() (ingest\_raw.Timer method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.join}}\pysiglinewithargsret{\sphinxbfcode{join}}{\emph{timeout=None}}{}
Wait until child process terminates

\end{fulllineitems}

\index{name (ingest\_raw.Timer attribute)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.name}}\pysigline{\sphinxbfcode{name}}
\end{fulllineitems}

\index{pid (ingest\_raw.Timer attribute)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.pid}}\pysigline{\sphinxbfcode{pid}}
Return identifier (PID) of process or \sphinxtitleref{None} if it has yet to start

\end{fulllineitems}

\index{run() (ingest\_raw.Timer method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.run}}\pysiglinewithargsret{\sphinxbfcode{run}}{}{}
\end{fulllineitems}

\index{sentinel (ingest\_raw.Timer attribute)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.sentinel}}\pysigline{\sphinxbfcode{sentinel}}
Return a file descriptor (Unix) or handle (Windows) suitable for
waiting for process termination.

\end{fulllineitems}

\index{start() (ingest\_raw.Timer method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.start}}\pysiglinewithargsret{\sphinxbfcode{start}}{}{}
Start child process

\end{fulllineitems}

\index{terminate() (ingest\_raw.Timer method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.Timer.terminate}}\pysiglinewithargsret{\sphinxbfcode{terminate}}{}{}
Terminate process; sends SIGTERM signal or uses TerminateProcess()

\end{fulllineitems}


\end{fulllineitems}

\index{calculate\_sentiment() (in module ingest\_raw)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.calculate_sentiment}}\pysiglinewithargsret{\sphinxcode{ingest\_raw.}\sphinxbfcode{calculate\_sentiment}}{\emph{positive\_words}, \emph{negative\_words}, \emph{tweet\_text}}{}
\end{fulllineitems}

\index{getDateFromTimestamp() (in module ingest\_raw)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.getDateFromTimestamp}}\pysiglinewithargsret{\sphinxcode{ingest\_raw.}\sphinxbfcode{getDateFromTimestamp}}{\emph{timestamp}}{}
\end{fulllineitems}

\index{read\_tweets() (in module ingest\_raw)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.read_tweets}}\pysiglinewithargsret{\sphinxcode{ingest\_raw.}\sphinxbfcode{read\_tweets}}{\emph{path}, \emph{filename}}{}
\end{fulllineitems}

\index{threaded() (in module ingest\_raw)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{mongoDB_data_ingestion:ingest_raw.threaded}}\pysiglinewithargsret{\sphinxcode{ingest\_raw.}\sphinxbfcode{threaded}}{\emph{fn}}{}
\end{fulllineitems}



\chapter{Neo4j: API to generate cypher queries}
\label{\detokenize{neo4j_query_generation::doc}}\label{\detokenize{neo4j_query_generation:neo4j-api-to-generate-cypher-queries}}
Here we expalin the API to generate cypher queries for Neo4j.


\section{Template of a general query}
\label{\detokenize{neo4j_query_generation:template-of-a-general-query}}
Any query can be thought of as a 2 step process -
\begin{itemize}
\item {} 
Extract the relevant sub-graph satisfying the query constraints (Eg. Users and their tweets that use a certain hashtag)

\item {} 
Post-processing of this sub-graph to return desired result (Eg. Return “names” of such users, Return “number” of such users)

\end{itemize}

In a generic way, the 1st step can be constructed using AND,OR,NOT of multiple constraints. We now specify how each such constraint can be built.

We look at the network in an abstract in two dimensions.
\begin{itemize}
\item {} 
There are “Entities” (users and tweets) which have “Attributes” (like user has screen\_name,follower\_count etc. and tweet has hashtag,mentions etc.).

\item {} 
The entities have “Relations” between them which have the only attribute as time/time-interval (Eg. Follows “relation” between 2 user “entities” has a time-interval associated).

\end{itemize}

So each constraint can be specified by specifying a pattern consisting of
\begin{itemize}
\item {} 
Two Entities and their Attributes

\item {} 
Relation between the entities and its Attribute (which is the time constraint of this relation)

\end{itemize}

To make things clear we provide an example here.
Suppose our query is - Find users who follow a user with id=1 and have also tweeted with a hashtag “h” between time t1 and t2.
We first break this into AND of two constraints:
\begin{itemize}
\item {} 
User follows a user with id=1

\item {} 
User has tweeted with a hashtag “h” between time t1 and t2.

\end{itemize}

We now specify the 1st constraint using our entity-attribute abstraction.
\begin{itemize}
\item {} 
Source entity - User, Attributes - None

\item {} 
Destination entity - User, Attributes - id=1

\item {} 
Relationship - Follows, Attributes - None

\end{itemize}

We now specify the 2nd constraint using our entity-attribute abstraction.
\begin{itemize}
\item {} 
Source entity - User, Attributes - None

\item {} 
Destination entity - Tweet, Attributes - hashtag:”h”

\item {} 
Relationship - Follows, Attributes - b/w t1,t2

\end{itemize}

The missing thing in this abstraction is that we have not taken into account that the source entity in both the constraints refers to the same User. To do so, we “name” each entity (like a variable). So we have:
\begin{itemize}
\item {} \begin{description}
\item[{Constraint 1:}] \leavevmode\begin{itemize}
\item {} 
Source entity - u1:User, Attributes - None

\item {} 
Destination entity - u2:User, Attributes - id=1

\item {} 
Relationship - Follows, Attributes - None

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{Constraint 2:}] \leavevmode\begin{itemize}
\item {} 
Source entity - u1:User, Attributes - None

\item {} 
Destination entity - u3:Tweet, Attributes - hashtag:”h”

\item {} 
Relationship - Follows, Attributes - b/w t1,t2

\end{itemize}

\end{description}

\end{itemize}


\section{Creating a custom query through dashboard API : Behind the scenes}
\label{\detokenize{neo4j_query_generation:creating-a-custom-query-through-dashboard-api-behind-the-scenes}}
A user can follow the general template of a query as provided above to build a query.
when a user provides the inputs to specify the query, the following steps are executed on the server:
\begin{itemize}
\item {} 
Cleanup and processing of the inputs provided by the user.

\item {} 
The variables(User/Tweet) and the relations are stored in a database. These stored objects can be later used by the user.

\item {} 
The query specified by the user is converted into a Cypher neo4j graph mining query.

\item {} 
Connection is established with the neo4j server and the query is executed on the database.

\item {} 
The results obtained are concatenated and are displayed.

\end{itemize}


\section{Code Documentation}
\label{\detokenize{neo4j_query_generation:code-documentation}}
Here we provide a documentation of the code.
\phantomsection\label{\detokenize{neo4j_query_generation:module-generate_queries}}\index{generate\_queries (module)}
Module to generate cypher code for inputs taken from user though dashboard API.

The {\hyperref[\detokenize{neo4j_query_generation:module-generate_queries}]{\sphinxcrossref{\sphinxcode{generate\_queries}}}} module contains the classes:
\begin{itemize}
\item {} 
{\hyperref[\detokenize{neo4j_query_generation:generate_queries.CreateQuery}]{\sphinxcrossref{\sphinxcode{generate\_queries.CreateQuery}}}}

\end{itemize}

One can use the {\hyperref[\detokenize{neo4j_query_generation:generate_queries.CreateQuery.create_query}]{\sphinxcrossref{\sphinxcode{generate\_queries.CreateQuery.create\_query()}}}} to build a cypher query.

Example illustrating how to create a query which gives the userids and their tweet counts who have used a certian hashtag.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{actors}\PYG{o}{=}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{u}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{USER}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{t}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{TWEET}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{t1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{TWEET}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{attributes}\PYG{o}{=}\PYG{p}{[}\PYG{p}{[}\PYG{p}{]}\PYG{p}{,}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{hashtag}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}hash\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}\PYG{p}{[}\PYG{p}{]}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{relations}\PYG{o}{=}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{u}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{TWEETED}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{t}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{u}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{TWEETED}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{t1}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cq} \PYG{o}{=} \PYG{n}{CreateQuery}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{return\PYGZus{}values}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{u.id,count(t1)}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ret\PYGZus{}dict} \PYG{o}{=} \PYG{n}{cq}\PYG{o}{.}\PYG{n}{create\PYGZus{}query}\PYG{p}{(}\PYG{n}{actors}\PYG{p}{,}\PYG{n}{attributes}\PYG{p}{,}\PYG{n}{relations}\PYG{p}{,}\PYG{n}{return\PYGZus{}values}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{pprint}\PYG{p}{(}\PYG{n}{ret\PYGZus{}dict}\PYG{p}{,}\PYG{n}{width}\PYG{o}{=}\PYG{l+m+mi}{150}\PYG{p}{)}
\end{sphinxVerbatim}

Example of a query which uses time indexing in a relationship:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{actors} \PYG{o}{=} \PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{USER}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{u1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{USER}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]} \PYG{o}{+} \PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TWEET}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TWEET}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{attributes} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{id}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{12}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{id}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{24}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{]}\PYG{o}{+}\PYG{p}{[}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hashtag}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLUERISING}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{retweet\PYGZus{}of}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{has\PYGZus{}mention}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{u1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{relations} \PYG{o}{=} \PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{FOLLOWS}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{u1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{TWEETED}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{24}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{48}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{sphinxVerbatim}
\index{CreateQuery (class in generate\_queries)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{neo4j_query_generation:generate_queries.CreateQuery}}\pysigline{\sphinxbfcode{class }\sphinxcode{generate\_queries.}\sphinxbfcode{CreateQuery}}
Bases: \sphinxcode{object}

Class containing functions to generate query.
\index{conditional\_create() (generate\_queries.CreateQuery method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{neo4j_query_generation:generate_queries.CreateQuery.conditional_create}}\pysiglinewithargsret{\sphinxbfcode{conditional\_create}}{\emph{entity}}{}
Condionally provide the attributes of the node if not already created, else directly use the name of the variable create earlier.
If already create, pass empty list of properties.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{entity} \textendash{} the entity which to check and create

\item[{Returns}] \leavevmode
the code for the node as neo4j node enclosed in ()

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_query() (generate\_queries.CreateQuery method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{neo4j_query_generation:generate_queries.CreateQuery.create_query}}\pysiglinewithargsret{\sphinxbfcode{create\_query}}{\emph{actors}, \emph{attributes}, \emph{relations}, \emph{return\_values}}{}
Takes a list of attributes and relationships between them and return a cypher code as string.
For the format of the lists see the examples.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{actors} \textendash{} the variable names, types of the attributes

\item {} 
\sphinxstyleliteralstrong{attributes} \textendash{} the properties of the actors

\item {} 
\sphinxstyleliteralstrong{relations} \textendash{} the relations between the entities along with time index for the relations

\item {} 
\sphinxstyleliteralstrong{return\_values} \textendash{} a direct string containing the return directive.

\end{itemize}

\item[{Returns}] \leavevmode
index of the bond in the molecule

\end{description}\end{quote}

\begin{sphinxadmonition}{note}{Note:}
Here we are expecting that if user has not specified the times on the dashboard, then we pass epmty string. If you
store some other default in dashboard database then change this accordingly.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
The return \_values is directly used as a string in the cypher query, so the user can use AS and other similar cypher directives while specifying the query.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Todo:}
Support to compose queries using OR. For example, currently compostion of relationships or attribute properties like all tweets(t) which are retweets of t1 or quoted t2, is not supported. Use cypher union for this.
\end{sphinxadmonition}

\end{fulllineitems}

\index{generate\_node() (generate\_queries.CreateQuery method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{neo4j_query_generation:generate_queries.CreateQuery.generate_node}}\pysiglinewithargsret{\sphinxbfcode{generate\_node}}{\emph{var}, \emph{type}, \emph{props}}{}
Helper function for {\hyperref[\detokenize{neo4j_query_generation:generate_queries.CreateQuery.conditional_create}]{\sphinxcrossref{\sphinxcode{generate\_queries.CreateQuery.conditional\_create()}}}}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{var} \textendash{} the variable name of the entity

\item {} 
\sphinxstyleliteralstrong{type} \textendash{} the type of the entity. Observe we pass type as :USER and NOT as USER

\item {} 
\sphinxstyleliteralstrong{props} \textendash{} the properties of the entity.

\end{itemize}

\item[{Returns}] \leavevmode
the code for the node as neo4j node enclosed in ()

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Generating queries in mongoDB}
\label{\detokenize{mongoDB_query_generation::doc}}\label{\detokenize{mongoDB_query_generation:generating-queries-in-mongodb}}

\chapter{Composing multiple queries : DAG}
\label{\detokenize{dag::doc}}\label{\detokenize{dag:composing-multiple-queries-dag}}

\chapter{Generating alerts using flink and kafka}
\label{\detokenize{flink::doc}}\label{\detokenize{flink:generating-alerts-using-flink-and-kafka}}

\chapter{Benchmarking the query answering}
\label{\detokenize{benchmarking::doc}}\label{\detokenize{benchmarking:benchmarking-the-query-answering}}

\chapter{Dashboard Website}
\label{\detokenize{dashboard_website::doc}}\label{\detokenize{dashboard_website:dashboard-website}}

\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{g}
\item {\sphinxstyleindexentry{generate\_queries}}\sphinxstyleindexpageref{neo4j_query_generation:\detokenize{module-generate_queries}}
\indexspace
\bigletter{i}
\item {\sphinxstyleindexentry{ingest\_raw}}\sphinxstyleindexpageref{mongoDB_data_ingestion:\detokenize{module-ingest_raw}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}